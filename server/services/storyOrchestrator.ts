import { StoryRowData, StoryResult } from "../types";
import { PromptEngine } from "./PromptEngine";
import { sendToOpenAIWithTemperature } from "./openAI";
import { sendToGeminiWithTemperature } from "./googleGemini";
import { sendToClaudeWithTemperature } from "./anthropicAI";

export class StoryOrchestrator {
    private rows: StoryRowData[];
    private promptEngine: PromptEngine;
    private conversationHistory: string[] = [];

    constructor(rows: StoryRowData[], mainTemplate: string, dictionary: any) {
        this.rows = rows;
        this.promptEngine = new PromptEngine(mainTemplate, dictionary);
    }

    public async generateAll(): Promise<StoryResult[]> {
        const results: StoryResult[] = [];
        
        // Intro Context ì¶”ê°€
        if (this.rows.length > 0 && this.rows[0].introContext) {
            this.conversationHistory.push(`[System Intro]: ${this.rows[0].introContext}`);
        }

        console.log(`ğŸš€ Start Story Orchestration (${this.rows.length} rows)`);

        for (const row of this.rows) {
            // directionì´ ì—†ìœ¼ë©´ ìƒì„±ì„ ìŠ¤í‚µ
            if (!row.direction || row.direction.trim() === "") {
                continue;
            }

            console.log(`\nâ–¶ Processing [${row.key}] Speaker: ${row.speaker}`);

            try {
                // 1. í”„ë¡¬í”„íŠ¸ ìƒì„± (ì—¬ê¸°ì„œ ìºë¦­í„° íŒŒì¼ë„ ìë™ ë¡œë“œë¨)
                const prompt = this.promptEngine.buildPrompt(row, this.conversationHistory);

                // 2. ëª¨ë¸ ë¶„ê¸° ì²˜ë¦¬
                let generatedText = "";
                let inputText = `you are a story writer who is an expert of Visual Novel style game in scenario. your story is starting from ${row.introContext}`
                const modelKey = (row.model || "").toLowerCase();
                const temperature = (row.temperature || 0.5);
                
                switch (modelKey) {
                    case "claude" :
                        generatedText = await sendToClaudeWithTemperature(inputText, prompt, temperature);
                        break;
                    case "gpt" :
                        generatedText = await sendToOpenAIWithTemperature(inputText, prompt, temperature);
                        break;
                    case "gemini"  :
                        generatedText = await sendToGeminiWithTemperature(inputText, prompt, temperature);
                        break;
                    default:
                        throw new Error(`Unsupported model type: ${modelKey}`);
                }

                // 3. ê²°ê³¼ íŒŒì‹± (CSV í¬ë§· "key, text"ì—ì„œ textë§Œ ì¶”ì¶œ)
                const cleanText = this.parseOutput(generatedText, row.key);

                // 4. íˆìŠ¤í† ë¦¬ ëˆ„ì 
                this.conversationHistory.push(`${row.speaker}: ${cleanText}`);

                // 5. ê²°ê³¼ ìˆ˜ì§‘
                results.push({
                    key: row.key,
                    result: cleanText
                });

                console.log(`   âœ… Output: ${cleanText.substring(0, 40)}...`);

            } catch (error) {
                console.error(`   âŒ Error:`, error);
                results.push({ key: row.key, result: "[Error]" });
            }
        }

        return results;
    }

    private parseOutput(text: string, key: string): string {
        const parts = text.split(",");
        if (parts.length >= 2) {
            // ì²« ë²ˆì§¸ ì‰¼í‘œ ì´í›„ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•©ì¹¨ (ëŒ€ì‚¬ì— ì‰¼í‘œ í¬í•¨ ê°€ëŠ¥ì„±)
            return parts.slice(1).join(",").trim();
        }
        return text.replace(key, "").trim();
    }
}